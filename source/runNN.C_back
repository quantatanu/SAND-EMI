
void runNN(){
  //  TFile *input = new TFile("outmax2.root");

  TRandom *ran=new TRandom3(0);

  TFile *input=new TFile("/dune/app/users/anath/EDEP_ANALYSIS/muID/ATANUs/EXTMUID/OUTPUT/ROOT/out30_chi100.root");
  TTree *oldtree=(TTree*)input->Get("nntree");

  bool type;
  int BLlayer;
  bool pionNoIC5;
  oldtree->SetBranchAddress("type", &type );
  oldtree->SetBranchAddress("BLlayer", &BLlayer);
  oldtree->SetBranchAddress("pionNoIC5", &pionNoIC5 );
  //  oldtree->SetBranchAddress("mreco", &mreco );
  TFile* newf=new TFile("/dune/app/users/anath/EDEP_ANALYSIS/muID/ATANUs/EXTMUID/OUTPUT/ROOT/newtest2.root","recreate");
  TTree *nntree = oldtree->CloneTree(0);
  Long64_t nentries = oldtree->GetEntries();
  int nsig=0;
  int nbkg=0;
  for (Long64_t i=0;i<nentries; i++) {
    oldtree->GetEntry(i);
    if(BLlayer!=2) continue;
    if(type==0) {
      if(pionNoIC5) continue;
      nntree->Fill(); nbkg++;
    }
    else {
      //    if(ran->Rndm()<0.6) continue;
      nntree->Fill();
      nsig++;
    }
  }
  std::cout<<"nentries:"<<nentries<<" nsig:"<<nsig<<" nbkg:"<<nbkg<<std::endl;

//commenting out, atanu
  //return 0;
  double cellEmax,cellEr,cellNtot, cellEmin,cellEavg;
  double layerEmean,layerErms,layerEr,layerEL2,layerEmax,layerEmin;
  double layerNcellL0,layerNcellL1;
  double layerNcellmax;

  nntree->SetBranchAddress("type", &type );
  nntree->SetBranchAddress("cellEmax", &cellEmax );
  nntree->SetBranchAddress("cellEmin", &cellEmin );
  nntree->SetBranchAddress("cellEr", &cellEr );
  nntree->SetBranchAddress("cellNtot", &cellNtot );
  
  nntree->SetBranchAddress("layerEmean", &layerEmean );
  nntree->SetBranchAddress("layerErms", &layerErms );
  nntree->SetBranchAddress("layerEr", &layerEr );
  nntree->SetBranchAddress("layerEL2", &layerEL2 );
  nntree->SetBranchAddress("layerEmax", &layerEmax );
  nntree->SetBranchAddress("layerEmin", &layerEmin );
  
  nntree->SetBranchAddress("layerNcellL0", &layerNcellL0 );
  nntree->SetBranchAddress("layerNcellL1", &layerNcellL1 );

  nntree->SetBranchAddress("layerNcellmax",&layerNcellmax);
  
  TMultiLayerPerceptron *mlp = new TMultiLayerPerceptron
    ("@cellEmax,@cellNtot,@cellEr,@layerEmean,@layerErms,@layerEr,@layerEL2,@layerEmax,@layerEmin,@layerNcellmax:8:5:type", nntree, "Entry$%2", "(Entry$+1)%2");
  
  int ntrain = 200;
  mlp->Train(ntrain, "text, graph, update=10");
  //export a class for future analysis
  mlp->Export("nnTrainedchi110","c++");

  TCanvas *c1 = new TCanvas("c1", "mlp test");
  TString outname="nnresult_chi110.pdf";
  c1->Print(outname+"[");
  c1->Divide(2,2);
  // Use TMLPAnalyzer to see what it looks for
  TMLPAnalyzer ana(mlp);
  // Initialisation
  ana.GatherInformations();
  // output to the console
  ana.CheckNetwork();
  c1->cd(1);
  // shows how each variable influences the network
  ana.DrawDInputs();

  //c1->Print("inputImpact.png");
  c1->cd(2);
  // shows the network structure
  //TCanvas *c2 = new TCanvas("c2", "mlp test");
  mlp->Draw();

  c1->cd(3);
  // draws the resulting network
  ana.DrawNetwork(0,"type==1","type==0");
  //c1->Print("output.png");

  c1->cd(4);

  TFile *outf=new TFile("nnoutchi110.root","recreate");

  TH1F *hLHSig = new TH1F("hLHSig", "NN output", 200, -.5, 1.5);
  TH1F *hLHBac = new TH1F("hLHBac", "NN output", 200, -.5, 1.5);


  oldtree->SetBranchAddress("type", &type );
  oldtree->SetBranchAddress("cellEmax", &cellEmax );
  oldtree->SetBranchAddress("cellEmin", &cellEmin );
  oldtree->SetBranchAddress("cellEr", &cellEr );
  oldtree->SetBranchAddress("cellNtot", &cellNtot );

  oldtree->SetBranchAddress("layerEmean", &layerEmean );
  oldtree->SetBranchAddress("layerErms", &layerErms );
  oldtree->SetBranchAddress("layerEr", &layerEr );
  oldtree->SetBranchAddress("layerEL2", &layerEL2 );
  oldtree->SetBranchAddress("layerEmax", &layerEmax );
  oldtree->SetBranchAddress("layerEmin", &layerEmin );

  oldtree->SetBranchAddress("layerNcellL0", &layerNcellL0 );
  oldtree->SetBranchAddress("layerNcellL1", &layerNcellL1 );

  oldtree->SetBranchAddress("layerNcellmax",&layerNcellmax);



  double params[10];
  for (Long64_t i=0;i<nentries; i++) {
    oldtree->GetEntry(i);
    if(BLlayer!=2) continue;
    if(type==0 && pionNoIC5) continue;
    params[0] = cellEmax;
    params[1] = cellNtot;
    params[2] = cellEr;
    params[3] = layerEmean;
    params[4] = layerErms;
    params[5] = layerEr;
    params[6] = layerEL2;
    params[7] = layerEmax;
    params[8] = layerEmin;
    params[9] = layerNcellmax;
    if(type==0)
      hLHBac->Fill(mlp->Evaluate(0,params));
    else if(type==1)
      hLHSig->Fill(mlp->Evaluate(0,params));
  }

  hLHSig->SetStats(0);  

  
  double max=hLHSig->GetMaximum()>hLHBac->GetMaximum()?hLHSig->GetMaximum():hLHBac->GetMaximum();
  hLHSig->GetYaxis()->SetRangeUser(0,max*1.06);
  hLHSig->SetLineColor(kRed);
  hLHSig->SetFillStyle(3003);
  hLHSig->SetFillColor(kRed);
  hLHSig->Draw("hist");
  hLHSig->GetXaxis()->SetTitle("NN cut");
  hLHSig->GetYaxis()->SetTitle("nEvts (POT: 1 spill)");
 
  hLHBac->SetStats(0);
  hLHBac->SetLineColor(kBlue);
  hLHBac->SetFillStyle(3008);
  hLHBac->SetFillColor(kBlue);
  hLHBac->Draw("same hist");
  c1->Print(outname);
  ///////////

  std::cout << "c1->Print(outname): " << outname << "\n";


  c1->Print(outname+"]");
  std::cout << "c1->Print(outname+\"]\"): " << outname+"]" << "\n";

  outf->Write();
  outf->Close();

}
